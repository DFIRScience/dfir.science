---
layout: single
title: "Similarity Comparison with SDHASH (fuzzy hashing)"
date: '2012-09-06T19:05:00.002+09:00'
author: Joshua
tags:
- Fuzzy Hashing
- HowTo
modified_time: '2015-08-24T22:35:19.347+09:00'
blogger_id: tag:blogger.com,1999:blog-2701259639305045003.single-7666945031783408251
blogger_orig_url: https://DFIR.Science/2012/09/similarity-comparison-with-sdhash-fuzzy.html
---

Being a fan of <a href="http://ssdeep.sourceforge.net/" target="_blank">ssdeep</a>&nbsp;for fuzzy hashing, I was interested in <a href="http://www.dfrws.org/2011/proceedings/09-341.pdf" target="_blank">this article</a> comparing ssdeep to <a href="http://roussev.net/" target="_blank">sdhash</a>.<br /><br />As the article says, ssdeep basically breaks up a file into pieces, hashes each piece, and combines the produced hashes to create a hash for the whole file. Similarity for each piece of the file can then be calculated since small chunks of the file are examined. When comparing two files, the similarity of chunks will result in a similar hash.<br /><br />sdhash, on the other hand, uses probabilistic feature extraction to find features that are unlikely to happen randomly. The extracted features are hashed and put into a <a href="http://en.wikipedia.org/wiki/Bloom_filter" target="_blank">Bloom filter</a>. For the comparison of two files, Bloom filters are compared using a&nbsp;<a href="http://en.wikipedia.org/wiki/Hamming_distance" target="_blank">Hamming distance</a>&nbsp;measure. The more similar the filter, the lower the Hamming distance.<br /><br />The article <a href="http://www.dfrws.org/2011/proceedings/09-341.pdf" style="font-style: italic;" target="_blank">An Evaluation of&nbsp;Forensic&nbsp;Similarity Hashes</a>&nbsp;demonstrated that with the different approaches, sdhash appears to outperform ssdeep in many instances. Because of this, I took a closer look at sdhash.<br /><br />One of the more interesting features of sdhash is the ability to tell the command how many threads you want to spawn. In Roussev's <a href="http://roussev.net/pdf/2012-IFIP--scalable-data-correlation.pdf" target="_blank">paper</a> he talks about parallelization. He had 12 processors on a test machine, with 24 cores. In many of his tests he was spawning 24 threads.<br /><br />So, wanting to get a feel for sdhash I built it on a 2.4 Ghz Intel Core 2 Duo machine. Building was straightforward on OS X: make &amp;&amp; sudo make install<br /><blockquote class="tr_bq">$ sdhash --version<br />sdhash 2.3alpha by Vassil Roussev, Candice Quates, August 2012, rev 476<br />&nbsp; &nbsp; &nbsp; &nbsp;http://sdhash.org, license Apache v2.0</blockquote>When doing a comparison you first need to create a list of SDBFs (bloom filters) for the files of interest. The switches I was most&nbsp;interested&nbsp;in were:<br /><br /><blockquote class="tr_bq">&nbsp; -r [ --deep ] &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; generate SDBFs from directories and&nbsp;files<br />&nbsp; -g [ --gen-compare ] &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; generate SDBFs and compare all pairs<br />&nbsp; -c [ --compare ] &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; compare all pairs in SDBF file, or<br />&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; compare two SDBF files to each other</blockquote><br />So, let's say I had a corpus of illegal images in a folder (and potentially many sub-folders) named "evidence". I could create the hashes of each of the images using the command:<br /><blockquote class="tr_bq">$sdhash -r evidence/ &gt; illegal_images.sdbf</blockquote>In this case I am outputting the results to the file "illegal_images.sdbf" using a standard &gt;, but you can also use -o to specify the output file.<br /><br />If I then want to compare all the hashes in illegal_images.sdbf to hashes create from a new case, on the new machine I would have to create a sdbf (test_images.sdbf) file for the new hashes, and then compare:<br /><blockquote class="tr_bq">$sdhash -c illegal_images.sdbf test_images.sdbf</blockquote>The output will be the names of the two compared files, plus a score of similarity all&nbsp;separated&nbsp;by pipes ( | ). For an&nbsp;explanation&nbsp;about the scoring system please see <i><a href="http://www.sciencedirect.com/science/article/pii/S1742287612000370" target="_blank">Content triage with similarity digests: the M57 case study</a></i>:<br /><blockquote class="tr_bq">warnings.py|warnings.py|100<br />opera8-2png1txt/file2.png|flask.ui/static/jquery.js|005<br />opera8-2png1txt/file2.png|flask.ui/venv/bin/python|009<br />opera8-2png1txt/file2.png|opera8-2png1txt/request.txt|066</blockquote>As Roussev says in his papers, the score is a calculation of similarity. In other words, even if the score is 100, the files may not be <i>exactly</i>&nbsp;the same.<br /><br />To test this, I have a 3.3K text file named "Makefile". First, I create a md5 and fuzzy hash of the file:<br /><blockquote class="tr_bq">$sdhash Makefile &gt; make.sdbf</blockquote><b>Result: </b>MD5 (Makefile) = 4fe15b4cf1591cdfe92b7efd65d291ec<br /><blockquote class="tr_bq"><span style="font-size: x-small;">sdbf:03:8:Makefile:3417:sha1:256:5:7ff:160:1:50:AICBAiDMAAAAAoEACMAQAAAICA5gACQIgBAAQYAAAAACAhAAAFAEACIAIAoEAACCAAICAAAAAEgEEMCgQAACBAAACAAQAABCCCBSQFgACAAAABLAAiBCciCAAgAIAACIBCQAAgGAAAASJhAgAAAUAAgAACQAAIEAEAAIAAAIAIAAAAaQCAAQEgABAWABAAAAEAAAAAAik6CgAQEAAAAABRQUxwAAAEEGAAAACAAQAEAAABAAAAA8CAiAAAEpgIAkAAQGAAICCAYSBsIFEQCoiAAAQIYCAAAIAASAAAAMSCABOCAAAARAAAQAIAAEFIABAgACgAACAEAIDAIAAACEEg==&nbsp;</span></blockquote>Next, I modify "Makefile" to remove the first "# " (hash and a space), create an md5 and fuzzy hash again and compare.<br /><br /><b>Result:</b>&nbsp;MD5 (Makefile) = d7e9182ee1d8cb7c6ad41157637c7d62<br /><blockquote class="tr_bq"><span style="font-size: x-small;">sdbf:03:8:Makefile:3415:sha1:256:5:7ff:160:1:50:AICBAiDMAAAAAoEACMAQAAAICA5gACQIgBAAQYAAAAACAhAAAFAEACIAIAoEAACCAAICAAAAAEgEEMCgQAACBAAACAAQAABCCCBSQFgACAAAABLAAiBCciCAAgAIAACIBCQAAgGAAAASJhAgAAAUAAgAACQAAIEAEAAIAAAIAIAAAAaQCAAQEgABAWABAAAAEAAAAAAik6CgAQEAAAAABRQUxwAAAEEGAAAACAAQAEAAABAAAAA8CAiAAAEpgIAkAAQGAAICCAYSBsIFEQCoiAAAQIYCAAAIAASAAAAMSCABOCAAAARAAAQAIAAEFIABAgACgAACAEAIDAIAAACEEg==</span></blockquote>Comparison of fuzzy hashes:<br /><blockquote class="tr_bq">$sdhash -c make.sdbf make_change.sdbf&nbsp;</blockquote>Resulting in:<br /><blockquote class="tr_bq">Makefile|Makefile|100&nbsp;</blockquote>So from this we see that the MD5 hashes (4fe15b4cf1591cdfe92b7efd65d291ec and&nbsp;d7e9182ee1d8cb7c6ad41157637c7d62) changed dramatically - as expected. The result of sdhash, however, still returned a score of 100, meaning that the file is very similar, even if the content is slightly different. I may run more experiments to see how much the file can change before the score is reduced, but that is for a later day.<br /><br />Another feature I am interested in is the specification of the number of threads.<br /><blockquote class="tr_bq">&nbsp; -p [ --threads ] arg (=1) &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; compute threads to use</blockquote>Using this, we can (hopefully) easily utilize server farms to make the hash generation and comparison an easier task.<br /><br />My test machine has 1 processor with 2 cores. Running sdhash without specifying the -p flag, ran with 1 thread and used around 80% - 90% of the CPU. When 'sdhash -p 2' was specified, 2 threads were spawned, and 170% - 190% of the processor was used (both cores). So, using multiple processors is quite easy, however, it may not always be the best option. In one of his papers, Roussev claims that running some threads on multiple cores of the same processor may not result in increased&nbsp;performance, but instead a competition for the processor's time. This appeared to be the case in our brief experiment:<br /><br /><blockquote class="tr_bq">$ time sdhash -r . &gt; test.hashes<br />real<span class="Apple-tab-span" style="white-space: pre;"> </span>2m20.365s<br />user<span class="Apple-tab-span" style="white-space: pre;"> </span>0m57.093s<br />sys<span class="Apple-tab-span" style="white-space: pre;"> </span>1m11.767s<br />$ time sdhash -p 2 -r . &gt; test.hashes<br />real<span class="Apple-tab-span" style="white-space: pre;"> </span>2m38.744s<br />user<span class="Apple-tab-span" style="white-space: pre;"> </span>2m20.538s<br />sys<span class="Apple-tab-span" style="white-space: pre;"> </span>2m41.520</blockquote>&nbsp;So in other words, you may want to test to make sure they way you are processing is the most efficient. I was hashing only a few hundred files, and not doing any comparison. If this were thousands, the a lot of time might have been wasted.<br /><br />Roussev suggested creating hashes at the same time as imaging by redirecting the output of the suspect device to an image file and as an input to sdhash. He suggested <a href="http://dcfldd.sourceforge.net/" target="_blank">dcfldd</a>. I've not tried it, but if you could hash and image at the same time, there could be some definite time savings depending on your forensic process.<br /><br />Overall fuzzy hashing appears interesting for finding similarity, however, I would like to test this method against full-size images vs. thumbnails. Since this method is NOT content analysis, but instead feature selection of raw data, I would be&nbsp;surprised&nbsp;if it found much similarity between an image and a corresponding thumbnail. If anyone has tested this, please let a comment with your results.